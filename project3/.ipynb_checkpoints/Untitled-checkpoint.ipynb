{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838d30d-7631-49da-b1dd-2f4cfd458f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f2801e-61d8-40ea-a1a5-7c4d08e646d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "loader = TextLoader(r\"C:\\AI_DEMO\\AI_Projects\\project3\\untitled.txt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ad45d-b5f6-4a54-9f84-8d42b6608687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract plain text\n",
    "texts = [doc.page_content for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83372ac1-476c-4268-8349-89826f65e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chunk documents\n",
    "# ---------------------------\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks = splitter.split_documents(documents)\n",
    "chunk_texts = [chunk.page_content for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356509c0-ec72-4eeb-bb7a-9a3ea0f88b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Feature extraction for Random Forest\n",
    "# ---------------------------\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(chunk_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e78c2b6-fbb3-48ed-98ad-ad2aed2b145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demo: create dummy labels (leave types)\n",
    "labels = np.random.choice([\"casual\", \"sick\", \"maternity\", \"unpaid\"], size=len(chunk_texts))\n",
    "\n",
    "# Train/test split (optional for demo)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9371df50-8f33-46e4-8a64-999287adf623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train Random Forest\n",
    "# ---------------------------\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d324366-c1db-4a57-bab9-1200d4763162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 5: Load local LLM\n",
    "# ---------------------------\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"TheBloke/vicuna-7B-1.1-HF\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",                   # automatically assigns layers to devices\n",
    "    offload_folder=\"offload\",            # folder to temporarily store weights on disk\n",
    "    offload_state_dict=True,             # enable offloading\n",
    "    torch_dtype=\"auto\"                   # automatically choose float16 or float32\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab2b7b-4eeb-4429-84d1-282cd57f05ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 6: Demo query\n",
    "# ---------------------------\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=200\n",
    ")\n",
    "new_text = [\"Employees can take 12 days of casual leave per year\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4ab630-e740-46ba-93e1-1eef184a99e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Classify chunk\n",
    "X_new = vectorizer.transform(new_text)\n",
    "category = rf.predict(X_new)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384e4cf0-0e4a-4365-a5e9-f5b417ddb360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Generate summary\n",
    "prompt = f\"Summarize this {category} leave policy in one sentence:\\n{new_text[0]}\"\n",
    "summary = generator(prompt)[0][\"generated_text\"]\n",
    "\n",
    "print(\"Category:\", category)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc0292-a429-422e-ad35-5de6dc86394c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
